ğŸ—ï¸ Baidu-Tieba-Community-Topic-Data-Asset-Construction (è½»é‡ç‰ˆ)

ç™¾åº¦è´´å§ç¤¾åŒºä¸»é¢˜æ•°æ®èµ„äº§å»ºè®¾é¡¹ç›®ï¼ˆè½»é‡å¯è¿è¡Œç‰ˆï¼‰

ğŸ“˜ ä¸€ã€é¡¹ç›®ç®€ä»‹

è¯¥é¡¹ç›®æ¨¡æ‹Ÿâ€œç™¾åº¦è´´å§â€ç¤¾åŒºè®ºå›ä¸»é¢˜æ•°æ®èµ„äº§å»ºè®¾çš„å®Œæ•´æµç¨‹ï¼Œ
ä» æ•°æ®é‡‡é›† â†’ æ¸…æ´— â†’ æ±‡æ€» â†’ åº”ç”¨å±‚åˆ†æ â†’ ç»“æœå¯¼å‡ºï¼Œ
æ—¨åœ¨å±•ç¤ºè½»é‡çº§æ•°ä»“çš„æ„å»ºä¸æŒ‡æ ‡ä½“ç³»æ­å»ºè¿‡ç¨‹ã€‚

å¯åœ¨ä¸ªäºº Hadoop + Hive ç¯å¢ƒä¸­ä¸€é”®è¿è¡Œã€‚

ğŸ“ äºŒã€é¡¹ç›®ç›®å½•ç»“æ„
/root/baidu_tieba_dw/
â”‚
â”œâ”€â”€ data/                      # æ¨¡æ‹ŸåŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ gen_data.py            # ç”Ÿæˆæ ·ä¾‹CSVæ•°æ®
â”‚   â”œâ”€â”€ user_info.csv
â”‚   â”œâ”€â”€ post_info.csv
â”‚   â””â”€â”€ comment_info.csv
â”‚
â”œâ”€â”€ scripts/                   # Hive & Shellè„šæœ¬
â”‚   â”œâ”€â”€ load_to_hdfs.sh        # ä¸Šä¼ æ•°æ®è‡³HDFS
â”‚   â”œâ”€â”€ hive_create_all.sql    # å»ºç«‹ODSå±‚è¡¨
â”‚   â”œâ”€â”€ hive_dwd_clean.sql     # æ¸…æ´—å¹¶ç”ŸæˆDWDå±‚
â”‚   â”œâ”€â”€ hive_dws_summary.sql   # æ±‡æ€»ç”ŸæˆDWSå±‚
â”‚   â”œâ”€â”€ hive_ads_analysis.sql  # è¾“å‡ºADSå±‚æŒ‡æ ‡
â”‚
â””â”€â”€ README.txt


ğŸ“Œ åˆ›å»ºå‘½ä»¤ï¼š

mkdir -p ~/baidu_tieba_dw/{data,scripts}
cd ~/baidu_tieba_dw

âš™ï¸ ä¸‰ã€ç¯å¢ƒè¦æ±‚
ç»„ä»¶	è¦æ±‚ç‰ˆæœ¬	æ£€æŸ¥å‘½ä»¤
Hadoop	3.x	hadoop version
HDFS	å·²å¯åŠ¨	hdfs dfs -ls /
Hive	3.x	hive --version
Python	â‰¥3.7	python3 --version
ğŸ§± å››ã€æ•°æ®ç”Ÿæˆï¼ˆ~/baidu_tieba_dw/data/gen_data.pyï¼‰
import random, csv
from datetime import datetime, timedelta

users = [f"user_{i}" for i in range(1, 51)]
forums = ["AIå§", "ç¼–ç¨‹å§", "æ¸¸æˆå§", "è€ƒç ”å§"]

# --- ç”¨æˆ·è¡¨ ---
with open("user_info.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["user_id", "register_time", "user_level"])
    for u in users:
        writer.writerow([u, (datetime.now() - timedelta(days=random.randint(0, 600))).strftime("%Y-%m-%d"), random.randint(1, 10)])

# --- å¸–å­è¡¨ ---
with open("post_info.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["post_id", "title", "user_id", "forum_name", "create_time", "reply_count", "like_count"])
    for i in range(1, 501):
        writer.writerow([
            i,
            f"å¸–å­æ ‡é¢˜_{i}",
            random.choice(users),
            random.choice(forums),
            (datetime.now() - timedelta(days=random.randint(0, 90))).strftime("%Y-%m-%d %H:%M:%S"),
            random.randint(0, 100),
            random.randint(0, 500)
        ])

# --- è¯„è®ºè¡¨ ---
with open("comment_info.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["comment_id", "post_id", "user_id", "comment_content", "comment_time"])
    for i in range(1, 1001):
        writer.writerow([
            i,
            random.randint(1, 500),
            random.choice(users),
            random.choice(["ä¸é”™", "æ”¯æŒ", "å­¦ä¹ äº†", "é¡¶", "æ°´è´´", "å¹¿å‘Š", "å“ˆå“ˆ"]),
            (datetime.now() - timedelta(days=random.randint(0, 90))).strftime("%Y-%m-%d %H:%M:%S")
        ])


ğŸ“Œ è¿è¡Œå‘½ä»¤ï¼š

cd ~/baidu_tieba_dw/data
python3 gen_data.py


âœ… ç”Ÿæˆæ–‡ä»¶ï¼š

user_info.csv
post_info.csv
comment_info.csv

ğŸšš äº”ã€æ•°æ®å¯¼å…¥ï¼ˆ~/baidu_tieba_dw/scripts/load_to_hdfs.shï¼‰
#!/bin/bash

# åˆ›å»ºHDFSç›®å½•
hdfs dfs -mkdir -p /data/ods/baidu_tieba/user_info
hdfs dfs -mkdir -p /data/ods/baidu_tieba/post_info
hdfs dfs -mkdir -p /data/ods/baidu_tieba/comment_info

# ä¸Šä¼ æ•°æ®
hdfs dfs -put -f ../data/user_info.csv /data/ods/baidu_tieba/user_info/
hdfs dfs -put -f ../data/post_info.csv /data/ods/baidu_tieba/post_info/
hdfs dfs -put -f ../data/comment_info.csv /data/ods/baidu_tieba/comment_info/


ğŸ“Œ è¿è¡Œå‘½ä»¤ï¼š

cd ~/baidu_tieba_dw/scripts
bash load_to_hdfs.sh


âœ… éªŒè¯ä¸Šä¼ ï¼š

hdfs dfs -ls /data/ods/baidu_tieba/user_info/

ğŸ§® å…­ã€ODS å±‚ï¼ˆ~/baidu_tieba_dw/scripts/hive_create_all.sqlï¼‰
-- ç”¨æˆ·è¡¨
CREATE EXTERNAL TABLE IF NOT EXISTS ods_user_info (
  user_id STRING,
  register_time STRING,
  user_level INT
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/data/ods/baidu_tieba/user_info/';

-- å¸–å­è¡¨
CREATE EXTERNAL TABLE IF NOT EXISTS ods_post_info (
  post_id INT,
  title STRING,
  user_id STRING,
  forum_name STRING,
  create_time STRING,
  reply_count INT,
  like_count INT
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/data/ods/baidu_tieba/post_info/';

-- è¯„è®ºè¡¨
CREATE EXTERNAL TABLE IF NOT EXISTS ods_comment_info (
  comment_id INT,
  post_id INT,
  user_id STRING,
  comment_content STRING,
  comment_time STRING
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
LOCATION '/data/ods/baidu_tieba/comment_info/';


ğŸ“Œ æ‰§è¡Œå‘½ä»¤ï¼š

hive -f ~/baidu_tieba_dw/scripts/hive_create_all.sql


âœ… æ£€æŸ¥ï¼š

SHOW TABLES LIKE 'ods_%';
SELECT * FROM ods_post_info LIMIT 5;

ğŸ§¹ ä¸ƒã€DWD æ¸…æ´—å±‚ï¼ˆ~/baidu_tieba_dw/scripts/hive_dwd_clean.sqlï¼‰
-- æ¸…æ´—å¸–å­è¡¨
CREATE TABLE dwd_post_detail AS
SELECT
  post_id,
  title,
  user_id,
  forum_name,
  from_unixtime(unix_timestamp(create_time, 'yyyy-MM-dd HH:mm:ss')) AS create_time,
  IF(reply_count < 0, 0, reply_count) AS reply_count,
  IF(like_count < 0, 0, like_count) AS like_count
FROM ods_post_info
WHERE title IS NOT NULL AND user_id IS NOT NULL;

-- æ¸…æ´—è¯„è®ºè¡¨ï¼ˆå»é™¤å¹¿å‘Šã€æ°´è´´ï¼‰
CREATE TABLE dwd_comment_detail AS
SELECT
  comment_id,
  post_id,
  user_id,
  comment_content,
  from_unixtime(unix_timestamp(comment_time, 'yyyy-MM-dd HH:mm:ss')) AS comment_time
FROM ods_comment_info
WHERE comment_content NOT RLIKE 'å¹¿å‘Š|æ°´è´´|æ”¿æ²»|è¿æ³•';

-- æ¸…æ´—ç”¨æˆ·è¡¨
CREATE TABLE dwd_user_info AS
SELECT
  user_id,
  from_unixtime(unix_timestamp(register_time, 'yyyy-MM-dd')) AS register_time,
  user_level
FROM ods_user_info
WHERE user_id IS NOT NULL;


ğŸ“Œ æ‰§è¡Œå‘½ä»¤ï¼š

hive -f ~/baidu_tieba_dw/scripts/hive_dwd_clean.sql


âœ… æ£€æŸ¥ï¼š

SHOW TABLES LIKE 'dwd_%';
SELECT COUNT(*) FROM dwd_comment_detail;

ğŸ“Š å…«ã€DWS æ±‡æ€»å±‚ï¼ˆ~/baidu_tieba_dw/scripts/hive_dws_summary.sqlï¼‰
-- ç”¨æˆ·æ´»è·ƒæŒ‡æ ‡
CREATE TABLE dws_user_active AS
SELECT
  u.user_id,
  COUNT(DISTINCT p.post_id) AS post_count,
  SUM(p.reply_count) AS total_replies,
  SUM(p.like_count) AS total_likes
FROM dwd_user_info u
LEFT JOIN dwd_post_detail p ON u.user_id = p.user_id
GROUP BY u.user_id;

-- è´´å§çƒ­åº¦æŒ‡æ ‡
CREATE TABLE dws_forum_hot_rank AS
SELECT
  forum_name,
  COUNT(post_id) AS post_num,
  SUM(reply_count + like_count) AS activity_score
FROM dwd_post_detail
GROUP BY forum_name;

-- è¿‘30å¤©å‘å¸–è¶‹åŠ¿
CREATE TABLE dws_post_trend AS
SELECT
  date_format(create_time,'yyyy-MM-dd') AS day,
  COUNT(*) AS post_count
FROM dwd_post_detail
WHERE create_time >= date_sub(current_date(),30)
GROUP BY date_format(create_time,'yyyy-MM-dd');


ğŸ“Œ æ‰§è¡Œå‘½ä»¤ï¼š

hive -f ~/baidu_tieba_dw/scripts/hive_dws_summary.sql


âœ… æ£€æŸ¥ï¼š

SELECT * FROM dws_forum_hot_rank;

ğŸ§  ä¹ã€ADS åº”ç”¨å±‚ï¼ˆ~/baidu_tieba_dw/scripts/hive_ads_analysis.sqlï¼‰
-- ç”¨æˆ·åˆ†å±‚æ ‡ç­¾
CREATE TABLE ads_user_tag AS
SELECT
  user_id,
  CASE 
    WHEN total_replies + total_likes > 400 THEN 'é«˜æ´»è·ƒ'
    WHEN total_replies + total_likes BETWEEN 100 AND 400 THEN 'ä¸­æ´»è·ƒ'
    ELSE 'ä½æ´»è·ƒ'
  END AS user_tag
FROM dws_user_active;

-- çƒ­å¸–æ¦œTop10
CREATE TABLE ads_hot_post AS
SELECT
  post_id,
  title,
  user_id,
  forum_name,
  (reply_count + like_count) AS hot_score
FROM dwd_post_detail
ORDER BY hot_score DESC
LIMIT 10;

-- å„è´´å§ç»¼åˆæ’å
CREATE TABLE ads_forum_rank AS
SELECT
  forum_name,
  post_num,
  activity_score,
  RANK() OVER (ORDER BY activity_score DESC) AS rank_id
FROM dws_forum_hot_rank;


ğŸ“Œ æ‰§è¡Œå‘½ä»¤ï¼š

hive -f ~/baidu_tieba_dw/scripts/hive_ads_analysis.sql


âœ… æ£€æŸ¥ï¼š

SELECT * FROM ads_user_tag LIMIT 10;
SELECT * FROM ads_hot_post LIMIT 10;
SELECT * FROM ads_forum_rank LIMIT 10;

ğŸ“¤ åã€ç»“æœå¯¼å‡º
hive -e "SELECT * FROM ads_hot_post;" > ~/baidu_tieba_dw/hot_post_result.csv

ğŸš€ åä¸€ã€æ‰§è¡Œé¡ºåºæ€»ç»“è¡¨
é˜¶æ®µ	å‘½ä»¤ / æ–‡ä»¶	è¯´æ˜
1ï¸âƒ£	python3 gen_data.py	ç”Ÿæˆæ¨¡æ‹ŸCSVæ•°æ®
2ï¸âƒ£	bash load_to_hdfs.sh	å¯¼å…¥HDFS
3ï¸âƒ£	hive -f hive_create_all.sql	å»ºç«‹ODSå±‚å¤–éƒ¨è¡¨
4ï¸âƒ£	hive -f hive_dwd_clean.sql	æ•°æ®æ¸…æ´—ä¸æ ‡å‡†åŒ–
5ï¸âƒ£	hive -f hive_dws_summary.sql	æ±‡æ€»ä¸æŒ‡æ ‡ç»Ÿè®¡
6ï¸âƒ£	hive -f hive_ads_analysis.sql	ç”Ÿæˆåº”ç”¨å±‚åˆ†æç»“æœ
7ï¸âƒ£	hive -e ... > csv	å¯¼å‡ºç»“æœä¸ºCSVæ–‡ä»¶
ğŸ“ˆ åäºŒã€æœ€ç»ˆè¾“å‡ºç»“æœ
è¡¨å	å†…å®¹è¯´æ˜
ads_user_tag	ç”¨æˆ·åˆ†å±‚æ ‡ç­¾
ads_hot_post	çƒ­å¸–æ¦œTop10
ads_forum_rank	å„è´´å§æ´»è·ƒåº¦æ’è¡Œ
ğŸ’¡ åä¸‰ã€åç»­æ‰©å±•å»ºè®®
åœºæ™¯	å»ºè®®
å¯è§†åŒ–å±•ç¤º	å¯å¯¼å…¥ Superset / FineBI å®ç° BI å±•ç¤º
æ•°æ®é‡æ‰©å¤§	è½¬ä¸º ORC/Parquet æ ¼å¼
è‡ªåŠ¨åŒ–è°ƒåº¦	å¯å¼•å…¥ Airflow / Azkaban å®ç°è°ƒåº¦
å­¦ä¹ æ‹“å±•	å¢åŠ â€œç”¨æˆ·ç•™å­˜åˆ†æâ€â€œå¸–å­ç”Ÿå‘½å‘¨æœŸåˆ†æâ€ç­‰æ¨¡å—
